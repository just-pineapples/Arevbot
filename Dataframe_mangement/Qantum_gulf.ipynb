{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aug 25 - Non-clipping\n",
    "#Sept 14 - Clipping \n",
    "#ALl of August\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\\\dpinales\\\\Desktop\\\\Energy_Opt\\\\data\\\\Eglin_Analysis\\\\Eglin - 9-14 CBX1.csv\")\n",
    "df2 = pd.read_csv(\"C:\\\\Users\\\\dpinales\\\\Desktop\\\\Energy_Opt\\\\data\\\\Eglin_Analysis\\\\Eglin - 9-14 CBX2.csv\")\n",
    "df3 = pd.read_csv(\"C:\\\\Users\\\\dpinales\\\\Desktop\\\\Energy_Opt\\\\data\\\\Eglin_Analysis\\\\Eglin - 9-14_MTR_POA.csv\")\n",
    "\n",
    "df_index = df1['Date (-05:00)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([df1.reset_index(drop=True),\n",
    "                    df2.reset_index(drop=True), \n",
    "                    df3.reset_index(drop=True)], axis=1,ignore_index=True)\n",
    "\n",
    "df_columns = [list(df1.columns),\n",
    "              list(df2.columns),\n",
    "              list(df3.columns),]\n",
    "\n",
    "flatten = lambda nested_list: [item for sublist in nested_list for item in sublist]\n",
    "all_df.columns = flatten(df_columns)\n",
    "\n",
    "for i in all_df.columns:\n",
    "    if \"Date (-05:00)\" in i:\n",
    "        new_df = all_df.drop([i], axis=1)\n",
    "\n",
    "\n",
    "new_df = new_df.set_index([df_index])\n",
    "new_df.index = pd.to_datetime(new_df.index)\n",
    "new_df = new_df[~new_df.index.duplicated(keep='first')]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Filters:\n",
    "        1. No Negative values for CBX\n",
    "        2. Meter filtered for 10% of MAX for MIN and 90% of MAX for Clipping\n",
    "        3. Irradiance above 200\n",
    "        4. Start at 11 am, Peak hours/No Shading\n",
    "Added Parameters: \n",
    "        5. DC Expected = daily_poa*string_count*IMP\n",
    "        6. Heat Map: Summation(DC_Current)/DC_Expected\n",
    "'''\n",
    "\n",
    "\n",
    "for i in new_df.columns:\n",
    "    if \"Recombiner\" in i:\n",
    "        filtered_df1 = new_df[new_df.loc[:,i] > 1]\n",
    "        \n",
    "meter_min = 30000000 * 0.10\n",
    "meter_max = 30000000 * 0.98\n",
    "\n",
    "\n",
    "filtered_df3 = filtered_df1[(filtered_df1.loc[:, \"Meter AC Power (W)\"]>meter_min)&(filtered_df1.loc[:, \"Meter AC Power (W)\"]<meter_max)&(filtered_df1.loc[:,\"Sensors - Irradiance reference (W/mÂ²)\"]>200)]\n",
    "\n",
    "filtered_df3 = new_df.between_time(\"9:00\", \"17:00\")\n",
    "filtered_df3[filtered_df3 <= 0.00] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cbx = []\n",
    "cbx_sum = []\n",
    "\n",
    "\n",
    "for x in filtered_df3:\n",
    "    if \"Recombiner\" in x:\n",
    "        cbx.append(x)\n",
    "        cbx_sum.append(filtered_df3[x].sum())\n",
    "        \n",
    "cbx_data = pd.DataFrame(cbx_sum, index=[cbx], columns=['Sum_of_CBX'])\n",
    "cbx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dates = filtered_df3.index\n",
    "fig_index = cbx_data.index\n",
    "fig_heatdf = cbx_data.filter([\"Estimated_Downstrings\", \"String_count\"])\n",
    "# fig_heatdf\n",
    "fig = px.density_heatmap(fig_heatdf, x=fig_heatdf.index.values,y=fig_dates,)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_downstrings = sum(down_strings)\n",
    "total_string = sum(string_count)\n",
    "ratio_strings = e_downstrings/total_string\n",
    "\n",
    "print(f\"The estimated plants DC outage: {ratio_strings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverters = pd.read_csv(\"data\\\\Eglin - Nonclipping_8-25 INV.csv\")\n",
    "inverters = inverters.set_index([df_index])\n",
    "inverters.index = pd.to_datetime(inverters.index)\n",
    "inverters = inverters[~inverters.index.duplicated(keep='first')]\n",
    "inverters = inverters.drop(\"Date (-05:00)\", axis=1)\n",
    "inverters = inverters.between_time(\"9:00\", \"17:00\")\n",
    "\n",
    "inv_sum = []\n",
    "inv = []\n",
    "\n",
    "\n",
    "for x in inverters.columns:\n",
    "    if \"INV\" in x:\n",
    "        inv.append(x)\n",
    "        inv_sum.append(inverters[x].sum())\n",
    "inv_df = pd.DataFrame(inv_sum, index=[inv], columns=['Sum_of_inv'])\n",
    "inv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Summation of CMB/INV'''\n",
    "\n",
    "\n",
    "sum_of_cbx = cbx_data['Sum_of_CBX']\n",
    "sum_of_inv = inv_df['Sum_of_inv']\n",
    "\n",
    "def cmb_summation(a,b):\n",
    "    total = (a/b)\n",
    "    return total\n",
    "\n",
    "\n",
    "cmb1 = []\n",
    "blk1_sum = []\n",
    "_summation1 = []\n",
    "\n",
    "inv1 = []\n",
    "inv1_blk = []\n",
    "\n",
    "for inv_range in range(100, 108, 1):\n",
    "    inv1.append(sum_of_inv.filter(like=str(inv_range), axis=0))\n",
    "\n",
    "for i in range(1, len(inv1)):\n",
    "    _inv1 = (sum(inv1[i]))\n",
    "    inv1_blk.append(_inv1)    \n",
    "\n",
    "for cmb_range in range(100, 108, 1):\n",
    "    cmb1.append(sum_of_cbx.filter(like=str(cmb_range), axis=0))\n",
    "\n",
    "for i in range(1,len(cmb1)):\n",
    "    _cb1 = (sum(cmb1[i]))\n",
    "    blk1_sum.append(_cb1)\n",
    "\n",
    "for (v, n) in zip(blk1_sum, inv1_blk):\n",
    "    _summation1.append(cmb_summation(v, n))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv2_dc = {\n",
    "    \"INV1\",\n",
    "    \"INV2\",\n",
    "    \"INV3\",\n",
    "    \"INV4\",\n",
    "    \"INV5\",\n",
    "    \"INV6\",\n",
    "    \"INV7\",\n",
    "}\n",
    "\n",
    "\n",
    "cmb2 = []\n",
    "blk2_sum = []\n",
    "\n",
    "inv2 = []\n",
    "inv2_blk = []\n",
    "\n",
    "_summation2 = []\n",
    "\n",
    "for inv_range in range(200, 208, 1):\n",
    "    inv2.append(sum_of_inv.filter(like=str(inv_range), axis=0))\n",
    "\n",
    "for i in range(1, len(inv2)):\n",
    "    _inv2 = (sum(inv2[i]))\n",
    "    inv2_blk.append(_inv2)    \n",
    "\n",
    "for cmb_range in range(200, 208, 1):\n",
    "    cmb2.append(sum_of_cbx.filter(like=str(cmb_range), axis=0))\n",
    "\n",
    "for i in range(1,len(cmb2)):\n",
    "    _cb2 = (sum(cmb2[i]))\n",
    "    blk2_sum.append(_cb2)\n",
    "\n",
    "for (v, n) in zip(blk2_sum, inv1_blk):\n",
    "    _summation2.append(cmb_summation(v, n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_summation = list(zip(_summation1, _summation2))\n",
    "\n",
    "cbx_over_inv = pd.DataFrame(total_summation, index=[n for n in inv2_dc.keys()],columns=['BLK1 CBX100-107/INV DC', \"BLK2 CBX200-207/INV DC\"])\n",
    "cbx_over_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbx_data.to_csv(\"Gulf I - 9-14.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('energyopt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ee7ccf5c2b422db1bca515afce38c3760a7c212612fed475a8b1d4a95c1ac50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
